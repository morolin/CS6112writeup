\documentclass[times, 10pt]{article}

\usepackage{amsmath}
\usepackage{mathpartir}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{stmaryrd}
\usepackage{cite}
\usepackage{verbatim} 
\usepackage{setspace}

\newcommand{\union}{\cup}
\newcommand{\Union}{\bigcup}
\newcommand{\intersection}{\cap}
\newcommand{\thickbar}{\talloblong}
%\newcommand{\Skip}{\hbox{\bf skip}}

\def\Skip{\hbox{\tt skip}}
\def\Else{\hbox{\bf else}}
\def\mod{\hbox{\bf mod}}
\def\true{\hbox{\bf true}}
\def\false{\hbox{\bf false}}
\let\prsarrow = \mapsto
\def\citepunct{,}  
\def\citedash{-}
\setstretch{1.5}

\begin{document}

\title{Formalizing Communicating Hardware Processes}
\author{Stephen Longfield\\Alec Story\\Norris Xu}
\maketitle

\section{Introduction and Overview}
% Stephen

In this project, we apply conventional PL theory reasoning to the Communicating
Hardware Processes (CHP) language used by the Asynchronous VLSI group at
Cornell. 

Our first observation was that the CHP language is compiled down to the
handshaking expansion (HSE) language as the first step of the compilation
process, and HSE has far fewer primitives.  Therefore, we defined each construct
in CHP as being built from HSE primitives, and then reasoned about these simpler
structures.

While doing so, we observed that there were several programs that were
expressible in the CHP language, but not implementable in the HSE language, or
not implementable in the final hardware synthesis. We created programs to run
the static analyses to detect these unimplementable programs.

Additionally, we wanted to reason about programs in the CHP language in a way
consistent with the other concurrent process calculi.  Therefore, we built a
labeled transition system in the CHP language, and discussed how it related to
the HSE operational semantics that we had defined.  Once we had defined the LTS
semantics, we were able to use it to reason about simple equivalences.

\section{Asynchronous Computing}

Most modern computation is done using a synchronous methodology, where there is
a global clock that is used to synchronize between different computational
units.  Each computational unit guarantees that its signals will be valid and
ready to be used by the next stage by the end of the clock period, though they
need not make any guarantees about the signal before that point.  At the end of
each clock period, the signals are stored in state-holding elements to be used
for the next period of computation. 

In designing these circuits, a designer must take care that no computation ever
takes longer than the clock period to complete. Because this relies on
transistor timing simulation to determine, it is difficult to verify formally,
and may depend on things such as variations in temperature or manufacturing
process.

Alternatively, there exist several classes of asynchronous circuits, which do
not have the same clocking behavior, instead having the all of the
synchronization performed locally. These circuits have the advantages of
granting average case performance, and being easier to formally verify. In this
document, we will be focusing on the \emph{Quasi Delay Insensitive} (QDI) class
of asynchronous circuits, commonly viewed to be the ``most asynchronous'' class,
which makes the fewest assumptions about the underlying hardware.

One requirement of circuit behaviors that makes designing asynchronous hardware
more challenging is the fact that synchronization is done locally, and therefore
done with locally generated signals. For this synchronization to happen
correctly, these signals must not have glitches --- signals which appear to
transition, but in actuality do not. One way to guarantee this is to be certain
that any transition that can occur will eventually occur, forcing the system to
be strongly confluent.

A methodology which guarantees this property for QDI asynchronous circuits is
Alain Martin's synthesis method.  In this process, you begin with a high-level
description of the desired system in the \emph{Communicating Hardware Processes}
language, a derivative of Hoare's CSP, and make parallelism-increasing
transformations to turn it into a massively parallel system. This system is then
projected down onto only actions on Boolean shared variables, through the
process known as \emph{handshaking expansion}, which can then be further
translated into a CMOS-implementable circuit, but that transformation is outside
the scope of this paper.  We only target the shared-variable language.

This semantics of this synthesis process were described in Marcel Ren\'{e} van der
Goot's 1995 Phd thesis "Semantics of VLSI Synthesis", but were done in a
trace-theory based operational semantics significantly different from what is in
use in contemporary PL research, making it difficult to translate techniques
from current research into this field. Some methods for reasoning about the
compilation process have been proposed, such as Manohar's \emph{Behaviors},
introduced in the paper ``Slack Elasticity in Concurrent Computing'', but those
were again trace-based.

\section{CHP}
% Stephen

The Communicating Hardware Processes (CHP) language is the language commonly
used to describe asynchronous circuits at a high level.  A formal semantics will
be given for it in this document, but it is presented here informally.

As convention, variables are ranged over by lowercase letters, $a, b, c \ldots$,
channels are ranged over by uppercase letters from the beginning of the
alphabet, $A, B, C \ldots$ ,  and programs or program segments are ranged over
by uppercase letters from the second half of the alphabet, $P, Q, R \ldots$.
When we violate this convention, it will be explicitly mentioned.

\begin{itemize}

\item \textbf{Skip}: $\Skip$.  This statement does nothing.

\item \textbf{Assignment}: $x := \mathrm{b}$, where $\mathrm{b}$ is some Boolean
expression.  This statement means ``assign the value of $\mathrm{b}$ to $x$.'' The
statements $x\uparrow$ and $x\downarrow$ are shorthand for $x := \true$ and $x
:= \false$, respectively.

\item \textbf{Communication}: $A!\mathrm{b}$ is a statement meaning ``send the
value of $\mathrm{b}$ over channel $A$,'' and $B?x$ means ``receive a value over
channel $B$ and store it in variable $x$.''  Both sending and receiving are
blocking.

\item \textbf{Probe}: The Boolean $\overline{A}$ is true if and only if a
communication on channel $A$ can complete without suspending.  In our
formulation, we write $\overline{A!}$ to mean that the channel is trying to
send, and $\overline{A?}$ to mean that the channel is trying to receive, so the
opposite action can complete without suspending.  Note that this does not
guarantee that another program will not communicate with the channel and
invalidate the result of the probe, unless the probing program has exclusive
control over its end of the channel (which we have a mechanism to enforce).

\item \textbf{Selection}: $[G_1 \rightarrow P_1 \talloblong ... \talloblong G_n
\rightarrow P_n]$, where each $G_i$ is a Boolean expression, and each $P_i$ is a
statement.  This statement is executed by waiting for one of the guards to be
true, and then executing one statement with a true guard.  If the guards are not
mutually exclusive, we use the thin bar ($|$) instead of the thick bar
($\talloblong$). $[G]$ is used as a shorthand for $[G \rightarrow \Skip]$.

\item \textbf{Repetition}: $*[G_1 \rightarrow P_1 \talloblong ... \talloblong
G_n \rightarrow P_n]$. This statement is executed by choosing one of the true
guards and executing the corresponding statement, repeating until all guards
evaluate to false. If the guards are not mutually exclusive, we use the thin bar
($|$) instead of the thick bar ($\talloblong$). $*[P]$ is used as a shorthand for
$*[\true \rightarrow P]$.

\item \textbf{Sequential Composition}: $P;Q$.  This statement means ``execute
statement $P$, and then execute statement $Q$.''

\item \textbf{Parallel Composition}: $P || Q$.  This statement means ``execute
statement $P$ while simultaneously executing statement $Q$.''

\item \textbf{Simultaneous Composition}: $P \star Q$.  This statement means
``execute channel actions $P$ and $Q$ such that they start and complete
simultaneously.''

\end{itemize}

\section{HSE}
% Alec

The CHP that existing users expect has too many primitives to model cleanly,
having both implicitly shared variables and channels. These channels are
complex, supporting multi-channel synchronization and peeking at channel state.
Rather than model the whole of CHP directly, we model a HSE which contains only
the shared variables and selection statements from CHP.  For the purposes of
this paper, HSE refers to conventional HSE plus arbitrary state disambiguation;
conventional HSE requires explicit variables to track state, but we do not model
those.

\subsection{Grammar}
\begin{align*}
\mathrm{\ell} & :: = \top \; | \; \bot \\
\mathrm{b} & ::= \ell \; | \;  a \; | \;
                 \mathrm{b}_1 \wedge \mathrm{b}_2 \; | \;
                 \mathrm{b}_1 \vee \mathrm{b}_2 \; | \;
                 \lnot \mathrm{b} \\
\mathrm{P} & ::= a := \mathrm{b} \; | \; S \; | \; *S \; | \;
                 P_1; P_2 \; | \: P_1 || P_2 \; | \;
                 \mathtt{\Skip} \\
\mathrm{S} & ::=
    [ \mathrm{b}_1 \rightarrow P_1  \talloblong \; ... \;
      \talloblong \mathrm{b}_n \rightarrow P_n ] \; | \;
    [ \mathrm{b}_1 \rightarrow P_1 | \; ... \; | \mathrm{b}_n \rightarrow P_n ]
\end{align*}

\subsection{Operational Semantics}
\subsubsection{Booleans}

\begin{mathpar}
\inferrule* [left=Primitive]
    { }
    {\sigma \models \ell = \ell}

\inferrule* [left=Read]
    {[a = \ell] \in \sigma}
    {\sigma \models a = \ell}

\inferrule* [left=Neg]
    {\sigma \models \mathrm{b} = \ell}
    {\sigma \models \lnot \mathrm{b} = \lnot \ell}

\inferrule* [left=And]
    {\sigma \models \mathrm{b}_1 = \ell_1 \\
     \sigma \models \mathrm{b}_2 = \ell_2}
    {\sigma \models \mathrm{b}_1 \land \mathrm{b}_2 = \ell_1 \land \ell_2}

\inferrule* [left=Or]
    {\sigma \models \mathrm{b}_1 = \ell_1 \\ \sigma \models \mathrm{b}_2 = \ell_2}
    {\sigma \models \mathrm{b}_1 \lor \mathrm{b}_2 = \ell_1 \lor \ell_2}
\end{mathpar}

Behavior of a Boolean statement containing an uninitialized variable is
undefined.

\subsubsection{Processes}

\begin{mathpar}

\inferrule* [left=SkipSeq]
    { }
    {\Skip; P, \sigma \rightarrow P, \sigma}

\inferrule* [left=SkipPar]
    { }
    {\Skip || P, \sigma \rightarrow P, \sigma}

\inferrule* [left=ParCommute]
    { }
    {P_1 || P_2, \sigma \rightarrow P_2 || P_1, \sigma}
\end{mathpar}

\begin{mathpar}
\inferrule* [left=StepSeq]
    {P_1, \sigma \rightarrow P_1', \sigma'}
    {P_1; P_2, \sigma \rightarrow P_1'; P_2, \sigma'}

\inferrule* [left=StepPar]
    {P_1, \sigma \rightarrow P_1', \sigma'}
    {P_1 || P_2, \sigma \rightarrow P_1' || P_2, \sigma'}

\inferrule* [left=Assign]
    {\sigma \models \mathrm{b} = \ell}
    {a := \mathrm{b}, \sigma \rightarrow \Skip, \sigma[ a = \ell]}
\end{mathpar}

\begin{mathpar}
\inferrule* [left=SelectDet]
    {\sigma \models \mathrm{b}_1 = \bot \land \ldots \land
                    \mathrm{b}_{i-1} = \bot \land
                    \mathrm{b}_i = \top \land
                    \mathrm{b}_{i+1} = \bot \land \ldots \land
                    \mathrm{b}_n = \bot}
    {[\mathrm{b}_1 \rightarrow P_1 \thickbar \ldots \thickbar
      \mathrm{b}_i \rightarrow P_i \thickbar \ldots \thickbar
      \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow P_i, \sigma}

\inferrule* [left=SelectNonDet]
    {\sigma \models \mathrm{b}_i = \top}
    {[\mathrm{b}_1 \rightarrow P_1 | \ldots |
      \mathrm{b}_i \rightarrow P_i | \ldots |
      \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow P_i, \sigma}
\end{mathpar}

\begin{mathpar}
\inferrule* [left=Repeat]
    {S, \sigma \rightarrow P, \sigma}
    {*S, \sigma \rightarrow P; *S, \sigma}

\inferrule* [left=RepeatNoneDet]
    {\sigma \models \mathrm{b}_1 = \bot \land \ldots \land \mathrm{b}_n = \bot}
    {*[\mathrm{b}_1 \rightarrow P_1 \thickbar \ldots \thickbar
      \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow \Skip, \sigma}

\inferrule* [left=RepeatNoneNonDet]
    {\sigma \models \mathrm{b}_1 = \bot \land \ldots \land \mathrm{b}_n = \bot}
    {*[\mathrm{b}_1 \rightarrow P_1 | \ldots |
       \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow \Skip, \sigma}
\end{mathpar}


\section{CHP embedding into HSE}
% Norris/Stephen

\begin{comment}
\subsection{HSE Grammar}
\begin{align*}
    \ell & ::= \top \; | \bot \\
    \mathrm{b} & ::= a \; | \; \ell \; | \; \mathrm{b}_1 \wedge \mathrm{b}_2 \; | \; \mathrm{b}_1 \vee \mathrm{b}_2 \; | \; \lnot \mathrm{b} \\
    \mathrm{P} & ::= a := \mathrm{b} \; | \; S \; | \, *S \; | \; P_1; P_2 \; | \: P_1 || P_2 \; | \; \mathtt{skip} \\
    \mathrm{S} & ::= [ \mathrm{b}_1 \rightarrow P_1 \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] \; | \; [ \mathrm{b}_1 \rightarrow P_1 | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] \\
\end{align*}

\end{comment}


\subsection{CHP Grammar}
%%% TODO do we want to explicitly exclude things like x := \overline{A} and \neg \overline{A}?
\begin{align*}
    \ell & ::= \top \; | \bot \\
    \mathrm{b} & ::= a \; | \; \ell \; | \; \overline{A!} \; | \; \overline{A?} \; | \; \mathrm{b}_1 \wedge \mathrm{b}_2 \; | \; \mathrm{b}_1 \vee \mathrm{b}_2 \; | \; \lnot \mathrm{b} \\
    \mathrm{P} & ::= a := \mathrm{b} \; | \; S \; | \, *S \; | \; C \; | \; P_1; P_2 \; | \: P_1 || P_2 \; | \; \mathtt{skip} \\
    \mathrm{S} & ::= [ \mathrm{b}_1 \rightarrow P_1 \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] \; | \; [ \mathrm{b}_1 \rightarrow P_1 | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] \\
    \mathrm{C} & ::= A!\mathrm{b} \; | \; A?a \; | \; C_1 \star C_2
\end{align*}

The only terms appearing in this grammar but not the HSE grammar are:
$\overline{A!}$, $\overline{A?}$, $A!\mathrm{b}$, $A?a$, and $C_1 \star C_2$.
It suffices to give translations for just these extra terms; everything else
translates to its equivalent in HSE. We also need to pick an active end and a
passive end for each channel in order to translate into HSE.  We decide which
end of the channel (the sending end or the receiving end) should be active using
the static analysis below, and denote by $\rho \vDash A!$ the channel $A$ having
its sending end active, and $\rho \vDash A?$ the channel $A$ having its
receiving end active.  For simplicity, we restrict all channels to be Boolean
channels.

Note that the fire prevention static analysis (described below) allows us to assume that all
channels are end-to-end.

The chanel actions are encoded onto a set of three boolean variables: $A_a$ for
channel acknowledge, and $A_t$ and $A_f$ for channel data.

\subsection{Translation}

%We use $\{C\}$ as shorthand to indicate terms which are translations of channel
%actions in CHP.

\begin{align*}
    \overline{A!} & \Rightarrow (A_t \vee A_f) \\
    \overline{A?} & \Rightarrow A_a \\
    A!\mathrm{b} & \Rightarrow \left\{ \begin{matrix} [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [A_a]; A_t := \bot; A_f := \bot; [\neg A_a] & \qquad \rho \vDash A! \\
                                                      [A_a]; [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [\neg A_a]; A_t := \bot; A_f := \bot & \qquad \rho \vDash A? \end{matrix} \right. \\
    A?a & \Rightarrow \left\{ \begin{matrix} [A_t \vee A_f]; a := A_t; A_a := \top; [\neg A_t \wedge \neg A_f]; A_a := \bot & \qquad \rho \vDash A! \\
                                             A_a := \top; [A_t \vee A_f]; a := A_t; A_a := \bot; [\neg A_t \wedge \neg A_f] & \qquad \rho \vDash A? \end{matrix} \right.
\end{align*}

For convenience, we make the following definitions:
\begin{align*}
    P(A!\mathrm{b}) & = A_a & P(A?a) & = A_t \vee A_f \\
    Q(A!\mathrm{b}) & = [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top] & Q(A?a) & = A_a := \top \\
    R(A!\mathrm{b}) & = A_t := \bot; A_f := \bot & R(A?a) & = a := A_t; A_a := \bot \\
    S(A!\mathrm{b}) & = \mathsf{skip} & S(A?a) & = a := A_t \\
    T(A!\mathrm{b}) & = \rho \vDash A! & T(A?a) & = \rho \vDash A?
\end{align*}
$P(C)$ and $T(C)$ are booleans, while $Q(C)$, $R(C)$, and $S(C)$ are code
fragments. Using these definitions, we can write the translations much more
concisely:
$$
    C \Rightarrow \begin{cases}
        Q(C); [P(C)]; S(C); R(C); [\neg P(C)] & T(C) \\
        [P(C)]; S(C); Q(C); [\neg P(C)]; R(C) & \neg T(C)
    \end{cases}
$$
where $C$ is any basic channel action (either $A!\mathrm{b}$ or $A?a$). We make
some more definitions for ease of writing the translations for complex channel
actions (here $C = C_1 \star \ldots \star C_n$):
\begin{align*}
    P(C) & = P(C_1) \wedge \ldots \wedge P(C_n) & P_{-i}(C) & = P(C_1) \wedge \ldots \wedge P(C_{i - 1}) \wedge P(C_{i + 1}) \wedge \ldots \wedge P(C_n) \\
    P'(C) & = \neg P(C_1) \wedge \ldots \wedge \neg P(C_n) & P'_{-i}(C) & = \neg P(C_1) \wedge \ldots \wedge \neg P(C_{i - 1}) \wedge \neg P(C_{i + 1}) \wedge \ldots \wedge \neg P(C_n) \\
    Q(C) & = Q(C_1); \ldots; Q(C_n) & Q_{-i}(C) & = Q(C_1); \ldots; Q(C_{i - 1}); Q(C_{i + 1}); \ldots; Q(C_n) \\
    R(C) & = R(C_1); \ldots; R(C_n) & R_{-i}(C) & = R(C_1); \ldots; R(C_{i - 1}); R(C_{i + 1}); \ldots; R(C_n) \\
    S(C) & = S(C_1); \ldots; S(C_n) & S_{-i}(C) & = S(C_1); \ldots; S(C_{i - 1}); S(C_{i + 1}); \ldots; S(C_n)
\end{align*}
It is worth noting that in the definitions for $Q(C), Q_{-i}(C), R(C),
R_{-i}(C), S(C), S_{-i}(C)$, we could replace the sequential compositions with
parallel compositions and the translation would still be correct.

We require a group of simultaneous channel actions $C_1 \star \ldots \star C_n$
to have at most one active channel action (i.e. at most one $C_i$ such that
$T(C_i)$ is true). The reason for this requirement is explained later. In the
case where $C_i$ is active and the rest of the $C_j$ are passive (i.e. only
$T(C_i)$ is true), we have:
$$ C_1 \star \ldots \star C_n \Rightarrow [P_{-i}(C)]; Q(C_i); [P(C_i)]; S_{-i}(C); Q_{-i}(C); [P'_{-i}(C)]; S(C_i); R(C_i); [\neg P(C_i)]; R_{-i}(C) $$
In the case where none of the $C_i$ are active (i.e. none of the $T(C_i)$ are
true), we have:
$$ C_1 \star \ldots \star C_n \Rightarrow [P(C)]; S(C); Q(C); [P'(C)]; R(C) $$

\section{Restrictions and Static Analysis}
%Alec

\subsection{Concurrent Write Prevention}

When our language is implemented on hardware, if we ever have two concurrent
programs writing two different values to the same variable simultaneously,
voltage connects to ground through the variable --- a short circuit --- and may
literally cause the circuit to catch fire.  To prevent this from happening, we
provide a static analysis method that tracks which variables a program may write
to, and prohibits potentially parallel processes from writing to the same
variables.  Because HSE is Turing-complete modulo infinite memory, we take a
worst-case evaluation of select statements.

This is accomplished by simple tree traversal over the AST.  Writes to variables
only occur in three places:

\begin{description}
\item[Variable Assignment:] The variable being written to.
\item[Channel Sends:] The data variables of the channel
\item[Channel Receives:] The acknowledge variable of the channel, and the
variable that we store the result into.
\end{description}

By traversing a program and accumulating the variables written, we can generate
a set of variables that that program may write to.  With this ability, we just
need to check whether these variable sets intersect when we introduce
parallelism.

The first and most obvious cases is across the parallel composition operator
$||$.  If a variable may be written to on both sides of the operator, we have a
potential fire.

%%% TODO adapt to star
More subtly, the bullet combinator for channel actions also introduces
parallelism (and, indeed, when we compile to HSE, it compiles into parallel
composition), and may cause fires.  For example, consider $A?x \bullet B?x$.
This may write conflicting values to the variable x simultaneously, and cause a
fire.  Traversing all the components of a bullet and building the variable sets
as we do for parallel composition prevents this from occurring.

One desirable side-effect of this restriction is that it forces all channels to
only have two concurrent endpoints at any time (they are \emph{end-to-end}):  if
two separate parallel processes could write to or read from the same channel,
there would be a potential fire on that channel's data or acknowledge variables.
This restriction ensures that the channels of CHP are easy to implement in
hardware --- while multi-endpoint channels are possible, they are very complex,
and require a lot of assumptions about the behavior of the corresponding
programs to function correctly, and the same functionality could be achieved by
just having a process mediate between the channels.  Note that this restriction
does not apply to probes, since they are strictly read only.

Additionally, we could have had the fire detection run post-translation into
HSE.  Any fire that occurs in CHP will also occur post-translation, and as it
stands, fire detection has to understand the basics of transforming channels
into variables. As fire detection places limits on the complexity of the
programs described (end-to-end channels for example), requiring that a program
be fire-free makes translation simpler.  For example, deriving correct bullet
transformations with possibly non-end-to-end channels would be extremely
difficult.

\subsection{A Type System for Channel Directionality}

When channels are implemented via transformation into variable reads and sets
using a handshake, one end of the channel waits first, and one end of the
channel writes first.  Either the sender or receiver can act first; a channel is
\emph{active} if the sender acts first, and \emph{passive} if the receiver acts
first.  We define the \emph{active end} of a channel as the end of the channel
that moves first; this is the sender for active channels and the receiver for
passive channels. We refer to this property of channels as \emph{directionality}.

%%% TODO adapt to star
Before we can transform CHP channels into HSE variables, we need to determine
the directionality of all the channel.  If there are no other restrictions on
channels, they can be assigned a directionality arbitrarily.  However, probes
and bullets place restrictions on the directionality of channels:

A probe can only probe the active end of a channel, because it listens for the
beginning of a channel action, and a wait is done silently, and cannot be
detected without interfering with the channel.

Bullets require that at most one of the channel ends in the bullet may be
active.  This requirement comes, too, from the implementation:  bullets must act
simultaneously, and HSE (and QDI circuits) provides a mechanism for synchronous
waiting, but not for synchronous writing to variables.

The bullet requirement can become difficult to solve since many bullets may be
entangled through channels that they share.  Fortunately, we can reduce this
problem to 2-SAT, where each channel is mapped to a variable of the same name,
and if that variable is true, then the channel is active:
\begin{align*}
\overline{A!} & \mapsto (A \lor A) \\
\overline{A?} & \mapsto (\lnot A \lor \lnot A) \\
A! \bullet B! & \mapsto (\lnot A \lor \lnot B) \\
A! \bullet B? & \mapsto (\lnot A \lor B) \\
A? \bullet B? & \mapsto (A \lor B)
\end{align*}

If we apply these rules to build up a set of restrictions from each probe and
each pair of channel actions that share a bullet in the program, any variable
assignment that satisfies them will ensure that the above constraints are
satisfied.

We have implemented a 2-SAT solver using the Aspvall, Plass \& Tarjan strongly
connected component algorithm; it runs in quadratic time on the size of bullets
(since we have a rule for each pair), and otherwise linear time on the number of
probes and bullets.  For channels whose directionality is unrestricted, it
assigns the direction arbitrarily.

\section{Labeled Transition System for CHP}
% Norris

%%% TODO we may need to change match to work with star
We begin by defining a ternary relation and a function. First, we define
$\mathsf{match} \subseteq \mathbf{Labels} \times \mathbf{Labels} \times
\mathbf{Assignments}$ (where labels is the set of possible labels on
transitions, which can either be tau or a set of channel communications, and
assignments is a set of assignments of values to variables) as follows:
$$
    \frac{A \in \mathbf{Channels} \quad a \in \mathbf{Variables}}{(\{A!\ell\}, \{A?a : \ell\}, \{[a = \ell]\}) \in \mathsf{match}} \qquad
    \frac{(\delta, \delta', \Sigma) \in \mathsf{match}}{(\delta', \delta, \Sigma) \in \mathsf{match}} $$$$
    \frac{(\delta, \delta', \Sigma) \in \mathsf{match}}{(\delta \cup \{A!\ell\}, \delta' \cup \{A?a : \ell\}, \Sigma \cup \{[a = \ell\}) \in \mathsf{match}}
$$
Intuitively, $(\delta, \delta', \Sigma) \in \mathsf{match}$ means that the set
of communications in label $\delta$ is the complement (i.e. sends correspond
bijectively to receives) of communications in $\delta'$, and $\Sigma$ is the set
of assignments that occur as a result of carrying out those communications (i.e.
$a := \top \in \Sigma$ if and only if there is some channel receive writing
$\top$ into $a$ in either $\delta$ or $\delta'$).

Next, we define $\mathsf{head}: \mathbf{Programs} \rightarrow
2^{\mathbf{ChannelActions}}$ (where ChannelActions = ${A!, A?}$)as follows:
\begin{flalign*}
    \mathsf{head}(P || Q) & = \mathsf{head}(P) \cup \mathsf{head}(Q) \\
    \mathsf{head}(P ; Q) & = \mathsf{head}(P) \\
    \mathsf{head}(A!\ell) & = \{A!\} \\
    \mathsf{head}(A?a) & = \{A?\} \\
    \mathsf{head}(A!\ell \star C) & = \{A!\} \cup \mathsf{head}(C) \\
    \mathsf{head}(A?a \star C) & = \{A?\} \cup \mathsf{head}(C) \\
    \mathsf{head}(P) & = \varnothing \quad \text{for any other program $P$}
\end{flalign*}
Intuitively, $\mathsf{head}(P)$ returns the set of all chanel actions that are
currently executing.

We start with the Boolean reduction rules. Here, $P, \sigma$ are the enclosing
program $P$ and the current environment $\sigma$, respectively.
$$
    \frac{}{P, \sigma \models \ell = \ell} \qquad
    \frac{[a = \ell] \in \sigma}{P, \sigma \models a = \ell} \qquad
    \frac{P, \sigma \models \mathrm{b} = \ell}{P, \sigma \models \neg \mathrm{b} = \neg \ell} $$$$
    \frac{P, \sigma \models \mathrm{b} = \top}{P, \sigma \models \mathrm{b} \vee \mathrm{b}' = \top} \qquad
    \frac{P, \sigma \models \mathrm{b}' = \top}{P, \sigma \models \mathrm{b} \vee \mathrm{b}' = \top} \qquad
    \frac{P, \sigma \models \mathrm{b} = \bot \quad P, \sigma \models \mathrm{b}' = \bot}{P, \sigma \models \mathrm{b} \vee \mathrm{b}' = \bot} $$$$
    \frac{P, \sigma \models \mathrm{b} = \bot}{P, \sigma \models \mathrm{b} \wedge \mathrm{b}' = \bot} \qquad
    \frac{P, \sigma \models \mathrm{b}' = \bot}{P, \sigma \models \mathrm{b} \wedge \mathrm{b}' = \bot} \qquad
    \frac{P, \sigma \models \mathrm{b} = \top \quad P, \sigma \models \mathrm{b}' = \top}{P, \sigma \models \mathrm{b} \wedge \mathrm{b}' = \top} $$$$
    \frac{A! \in \mathsf{head}(P)}{P, \sigma \models \overline{A!} = \top} \qquad
    \frac{A! \notin \mathsf{head}(P)}{P, \sigma \models \overline{A!} = \bot} \qquad
    \frac{A? \in \mathsf{head}(P)}{P, \sigma \models \overline{A?} = \top} \qquad
    \frac{A? \notin \mathsf{head}(P)}{P, \sigma \models \overline{A?} = \bot}
$$

%Here are the rules for CHP:
Continuing with the rules for statements in CHP (we use $\sigma \models$ as
shorthand for $P, \sigma \models$ to avoid having to include the entire text of
the program):

$$
    % skip, assign, sequential and parallel composition rules
    \frac{\langle P, \sigma \rangle \xrightarrow{\delta} \langle P', \sigma' \rangle}{\langle P ; Q, \sigma \rangle \xrightarrow{\delta} \langle P' ; Q, \sigma' \rangle} \qquad
    \frac{\langle P, \sigma \rangle \xrightarrow{\delta} \langle P', \sigma' \rangle}{\langle P || Q, \sigma \rangle \xrightarrow{\delta} \langle P' || Q, \sigma' \rangle} \qquad
    \frac{\langle P || Q, \sigma \rangle \xrightarrow{\delta} \langle R, \sigma' \rangle}{\langle Q || P, \sigma \rangle \xrightarrow{\delta} \langle R, \sigma' \rangle} \qquad
    \frac{\langle P || (Q || R), \sigma \rangle \xrightarrow{\delta} \langle S, \sigma' \rangle}{\langle (P || Q) || R, \sigma \rangle \xrightarrow{\delta} \langle S, \sigma' \rangle} $$$$
    \frac{}{\langle \mathtt{skip} || P, \sigma \rangle \xrightarrow{\tau} \langle P, \sigma \rangle} \qquad
    \frac{}{\langle \mathtt{skip}; P, \sigma \rangle \xrightarrow{\tau} \langle P, \sigma \rangle} \qquad
    \frac{\sigma \models \mathrm{b} = \ell}{\langle a := \mathrm{b}, \sigma \rangle \xrightarrow{\tau} \langle \mathtt{skip}, \sigma[a = \ell] \rangle} $$$$
    % selection rules
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_{i-1} = \bot \; \wedge \mathrm{b}_i = \top \wedge \mathrm{b}_{i+1} = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_n = \bot} {\langle [ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i , \sigma\rangle  } \qquad
    \frac{\sigma \models \mathrm{b}_i = \top} {\langle [ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i , \sigma\rangle  } $$$$
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \ldots \wedge \mathrm{b}_n = \bot}{\langle *[ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle \mathtt{skip} , \sigma\rangle } \qquad
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \ldots \wedge \mathrm{b}_n = \bot}{\langle *[ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle \mathtt{skip} , \sigma \rangle } $$$$
%   \frac{\langle S, \sigma \rangle \xrightarrow{\tau} \langle P, \sigma \rangle}{\langle *S, \sigma \rangle \xrightarrow{\tau} \langle P;*S, \sigma \rangle} $$$$
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_{i-1} = \bot \wedge \mathrm{b}_i = \top \wedge \mathrm{b}_{i+1} = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_n = \bot} {\langle *[ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i; \; *[ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma\rangle  } $$$$
    \frac{\sigma \models \mathrm{b}_i = \top} {\langle *[ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i;\;*[ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma\rangle  } $$$$
    % communication rules
    \frac{\sigma \models \mathrm{b} = \top}{\langle A!\mathrm{b}, \sigma \rangle \xrightarrow{A!\top} \langle \mathtt{skip}, \sigma \rangle} \qquad
    \frac{\sigma \models \mathrm{b} = \bot}{\langle A!\mathrm{b}, \sigma \rangle \xrightarrow{A!\bot} \langle \mathtt{skip}, \sigma \rangle} $$$$
    \frac{}{\langle A?a, \sigma \rangle \xrightarrow{A?a : \top} \langle \mathtt{skip}, \sigma[a = \top] \rangle} \qquad
    \frac{}{\langle A?a, \sigma \rangle \xrightarrow{A?a : \bot} \langle \mathtt{skip}, \sigma[a = \bot] \rangle} $$$$
    %\frac{\langle P, \sigma \rangle \xrightarrow{A!\ell} \langle P', \sigma \rangle \quad \langle Q, \sigma' \rangle \xrightarrow{A?a : \ell} \langle Q', \sigma'' \rangle}{\langle P || Q, \sigma \rangle \xrightarrow{\tau} \langle P' || Q', \sigma[a = \ell] \rangle} $$$$
    %\frac{\langle P, \sigma \rangle \xrightarrow{A?a : \ell} \langle P', \sigma' \rangle \quad \langle Q, \sigma'' \rangle \xrightarrow{A!\ell} \langle Q', \sigma'' \rangle}{\langle P || Q, \sigma \rangle \xrightarrow{\tau} \langle P' || Q', \sigma[a = \ell] \rangle}
    %%% TODO do we need to make any changes here?
    \frac{\langle P, \sigma \rangle \xrightarrow{\delta} \langle P', \sigma' \rangle \quad \langle Q, \sigma'' \rangle \xrightarrow{\delta'} \langle Q', \sigma''' \rangle \quad (\delta, \delta', \Sigma) \in \mathsf{match}}{\langle P || Q, \sigma \rangle \xrightarrow{\tau} \langle P' || Q', \sigma[\Sigma] \rangle} $$$$
    % star rules
    \frac{\langle C, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle \quad \sigma \models \mathrm{b} = \top}{\langle A!\mathrm{b} \star C, \sigma \rangle \xrightarrow{\delta \cup \{A!\top\}} \langle \mathtt{skip}, \sigma'[A_t = \top, A_a = \top] \rangle} $$$$
    \frac{\langle C, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle \quad \sigma \models \mathrm{b} = \bot}{\langle A!\mathrm{b} \star C, \sigma \rangle \xrightarrow{\delta \cup \{A!\bot\}} \langle \mathtt{skip}, \sigma'[A_f = \top, A_a = \top] \rangle} $$$$
    \frac{\langle C, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle}{\langle A?a \star C, \sigma \rangle \xrightarrow{\delta \cup \{A?a : \top\}} \langle \mathtt{skip}, \sigma'[A_t = \top, A_a = \top, a = \top] \rangle} $$$$
    \frac{\langle C, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle}{\langle A?a \star C, \sigma \rangle \xrightarrow{\delta \cup \{A?a : \bot\}} \langle \mathtt{skip}, \sigma'[A_f = \top, A_a = \top, a = \top] \rangle} $$$$
$$

Where $\sigma$ is the environment, which in this case consists of a set of
mappings of variables to values.  We initialize $\sigma$ to include $A_a =
\bot$, $A_t = \bot$, $A_f = \bot$ for all channels $A$.  Furthermore, note that
the labels on the transitions are sets, since we can have several channel
operations occurring at once (via $\star$).

\section{LTS and HSE Equality}
% Norris
For anything aside from probes and channel actions, since the transition rules
in LTS and HSE are identical, it follows that the behavior is also identical.
Thus it is semantically correct to leave those as-is when translating from LTS
to HSE.

Thus we need only show that the translations of channel actions and probes (the
non-identity translations) preserve the semantics of the program. Incidentally,
due to the details of the hardware implementation, there are many programs that
appear valid in CHP, yet will not pass static analysis and thus cannot be
translated into HSE. We will discuss the correctness of the translation only for
programs that are both valid CHP and pass the static analyses.

\subsection{Basic Channel Actions}
The translation of the two basic channel actions is the \emph{four-phase
handshake}, which works as follows: every channel has three variables assigned
to it. For a channel $A$, our translation rules name these as $A_a$, $A_t$, and
$A_f$. When the program begins execution, all three of these variables are
initialized to false. In addition, for each channel, we must pick one of the
ends to be the active end, and the other to be the passive end. Thus there are
two cases.

The translations for the case where the sending end is passive (i.e. $\rho
\vDash A?$) are as follows:
\begin{flalign*}
    A!\mathrm{b} & \Rightarrow [A_a]; [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [\neg A_a]; A_t := \bot; A_f := \bot \\
    A?a & \Rightarrow A_a := \top; [A_t \vee A_f]; a := A_t; A_a := \bot; [\neg A_t \wedge \neg A_f]
\end{flalign*}

The translations for the case where the receiving end is passive (i.e. $\rho
\vDash A!$) are as follows:
\begin{flalign*}
    A!\mathrm{b} & \Rightarrow [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [A_a]; A_t := \bot; A_f := \bot; [\neg A_a] \\
    A?a & \Rightarrow [A_t \vee A_f]; a := A_t; A_a := \top; [\neg A_t \wedge \neg A_f]; A_a := \bot
\end{flalign*}

In order to prove that the translation is correct, we need to show that
evaluation of either a send $A!\mathrm{b}$ or a receive $A?a$ on its own will
become stuck, but evaluation of both in parallel will have the same semantics as
in the LTS: namely, both the send and the receive evaluate to $\mathsf{skip}$
and also $a$ is assigned the value $\mathrm{b}$. We also want to show that each
of the three channel variables $A_a$, $A_t$, and $A_f$ are reset to false
afterwards; since the three channel variables are all initialized to false and
reset to false after each channel action, and by end-to-endness only one channel
action can occur at a time for each channel, this is sufficient to prove that at
the beginning of each channel action they will all be false. Note as well that
by end-to-endness, the only code that can change the value of the channel
variables is the currently executing $A!\mathrm{b}$ and $A?a$.

We first consider the case where the sending end is passive. Then on its own,
evaluation of $A!\mathrm{b}$ will become stuck because $A_a$ is false, and the
first thing that $A!\mathrm{b}$ does is wait for $A_a$ to be true. Likewise,
evaluation of $A?a$, on its own, will become stuck: it will first set $A_a$ to
true, but then it waits for either $A_t$ or $A_f$ to be true, and they are both
false. When evaluated together, $A!\mathrm{b}$ cannot make any progress at all
until $A_a$ is true, so it blocks until $A?a$ sets $A_a$ to true. Now $A?a$
cannot make any progress until $A_t \vee A_f$ is true, so it blocks until
$A!\mathrm{b}$ progresses past the $[A_a]$ check and sets one of them to be
true. Since $A!\mathrm{b}$ does so using a deterministic selection, exactly one
of $A_t, A_f$ will be set to true; by the guards on the selection, we also know
that $A_t = \top$ if and only if $b = \top$; i.e. $A_t = b$. Now $A!\mathrm{b}$
blocks until $A_a$ is false, so only $A?a$ makes progress. It does so by
assigning $a := A_t$ and setting $A_a$ to false, but it now blocks until both
$A_t$ and $A_f$ are false. Since $A_t = b$, it follows that $a = b$, as desired.
$A!\mathrm{b}$ sets both to false and completes. However, there is now the
possibility that another $A!\mathrm{b}$ action begins evaluation before the
first $A?a$ notices that $A_t$ and $A_f$ are both false and terminates. This
does not break anything because the second $A!\mathrm{b}$ action would
immediately become stuck because $A_a$ is false. (It is impossible for another
$A?a$ action to begin, because channels are end-to-end and we haven't finished
evaluating the current $A?a$ action.) Eventually, $A?a$ notices that $A_t$ and
$A_f$ are both false and completes as well. We now have $a = b$ and $A_a = A_t =
A_f = \bot$, as desired.

Next, we consider the case where the receiving end is passive. Then on its own,
evaluation of $A?a$ will become stuck because both $A_t$ and $A_f$ are false,
and the first thing that $A?a$ does is wait for $A_t \vee A_f$ to be true.
Likewise, evaluation of $A!\mathrm{b}$, on its own, will become stuck: it will
first set either $A_t$ or $A_f$ to true, but then it waits for $A_a$ to be true.
Since $A!\mathrm{b}$ sets $A_t$ and $A_f$ using a deterministic guard, exactly one
of the two will be set to true; furthermore, it sets $A_t := \top$ if and only
if $b = \top$. Thus $A_t = b$ afterwards. When evaluated together, $A?a$ cannot
make any progress at all until $A_t$ or $A_f$ is true, so it blocks until
$A!\mathrm{b}$ sets one of them to to true. Now $A!\mathrm{b}$ cannot make any
progress until $A_a$ is true, so it blocks until $A?a$ progresses past the $[A_t
\vee A_f]$ check, assigns $a := A_t$, and sets $A_a$ to be true. Since $A_t =
b$, we now have $a = b$. Now $A?a$ blocks until both $A_t$ and $A_f$ are false,
so only $A!\mathrm{b}$ makes progress. It does so by setting $A_t$ and $A_f$ to
false, and blocks until $A_a$ is false. $A?a$ sets $A_a$ to false and completes.
However, there is now the possibility that another $A?a$ action begins
evaluation before the first $A!\mathrm{b}$ notices that $A_a$ is now false and
terminates. This does not break anything because the second $A?a$ action would
immediately become stuck because both $A_t$ and $A_f$ are false. (Again, it is
impossible for another $A!\mathrm{b}$ action to begin, because channels are
end-to-end and we haven't finished evaluating the current $A!\mathrm{b}$
action.)Eventually, $A!\mathrm{b}$ gets a chance to run and completes as well.
We now have $a = b$ and $A_a = A_t = A_f = \bot$, as desired.

\subsection{Complex Channel Actions}
In order to show that a complex channel action $C_1 \star \ldots \star C_n$ is
correct, we need to show that it acts the same way as each of its component
basic channel actions $C_i$, except that each component begins and completes
evaluation simultaneously. We define two actions to be \textit{simultaneous} if
as soon as one action completes, the other could complete by itself if it were
to run (it isn't waiting on any other thread). Note that the basic communication
action translations do follow this definition of simultaneity: we know that the
passive end will always complete first, because the active end waits for the
passive end to set some channel variables back to false. However, once the
passive end completes, those variables are now false, and the next time the
active end runs, it will complete without needing to wait for any other thread
(we know that those variables cannot be set to true in the interim because only
another passive action on that channel can change those variables, and such an
action is stuck until a new active action on that channel begins, which in turn
can only occur after the current active action ends).

We consider first the case where every component is passive, as that is the
simpler case. We begin by taking apart the translation and looking at what gets
executed and in which order per component $C_i$. While there is much
interleaving of the components, if we look at an individual component $C_i$, we
have executed exactly the basic passive communication action protocol:
$[P(C_i)]; S(C_i); Q(C_i); [\neg P(C_i)]; R(C_i)$. Furthermore, the code
fragments for each component are independent (and thus can be safely
interleaved) because each code fragment only reads from and writes to the
channel variables for that channel. Therefore, each component behaves
identically to its basic counterpart. Aside from interleaving the pieces of
code, the translation adds synchronization by waiting for all of the $P(C_i)$ to
be true simultaneously at the beginning before any individual component is
allowed to proceed, and likewise by waiting for all of the $P(C_i)$ to be false
simultaneously at the end. This synchronizes the components at those points.
Although there is still $R(C_i)$ to execute after the last synchronization,
$R(C_i)$ does not depend on any other thread, and so this still fits our
definition of simultaneity.

Next, we consider the case where $C_i$ is active and the rest of the $C_j$ are
passive. Again, we take the translation apart componentwise. The translation is
identical to the all-passive case, except interleaved with $Q(C_i); [P(C_i)];
S(C_i); R(C_i); [\neg P(C_i)]$, which is exactly the basic active communication
action protocol. The argument above showing that all of the passive components
are synchronized still holds; we need to show that the passive components are
also synchronized with the active component $C_i$. By waiting until
$[P_{-i}(C)]$ is true before executing $Q(C_i)$, we ensure that all of the
passive components have started execution before we allow the active component
to start execution. This fits our definition of simultaneity since $Q(C_i)$ can
execute without needing to wait on another thread. Finally, at the end, we wait
for $[\neg P(C_i)]$ before allowing the $R(C_j)$ to execute. This ensures that
the active component completes before the passive components are allowed to
complete; since each of the $R(C_j)$ execute without needing to wait on another
thread, this fits our definition of simultaneity.

\subsection{Probes}
Due to limitations of the hardware implementation, we can only ever probe the
active end of the channel, since the passive end makes no visible changes when
it is blocked on a channel action. Thus, for a channel with a passive receiving
end, the only probe allowed is a send probe ($\overline{A!}$); likewise, for a
channel with a passive sending end, the only probe allowed is a receive probe
($\overline{A?}$). Thus we only have one translation for each probe:
\begin{flalign*}
    \overline{A!} & \Rightarrow (A_t \vee A_f) \\
    \overline{A?} & \Rightarrow A_a
\end{flalign*}

The behaviour of a probe is defined to be the following: the probe should only
ever evaluate to true if the channel action that it is probing is trying to
evaluate. At all other times, it should evaluate to false. Furthermore, the
probe is allowed to evaluate to false even when the channel action that it is
probing is still executing, although we try to minimize this behaviour.

Showing that this is true is quite simple. The main thing to notice is that for
a probe on a channel $\overline{A!}$ or $\overline{A?}$, the only channel
actions whose translations change the variables that the probe's value depends
on are $A!\mathrm{b}$ and $A?a$, respectively (possibly included within a
$\star$). To be specific: $\overline{A!}$ depends on $A_t$ and $A_f$, and
$\overline{A?}$ depends on $A_a$. Only the translations of sends on $A$ will
ever change the value of either $A_t$ or $A_f$, and only the translation of
receives on $A$ will ever change the value of $A_a$. Thus we know that the value
of the probe will depend solely on the evaluation of the action that is being
probed. 

Furthermore, each of these translations at some point in its evaluation sets one
of $A_t, A_f$ or $A_a$ to true for send and receive, respectively (this occurs
in $Q$); this causes the respective probe to evaluate to true, as it should.
Then, before the evaluation of the action ends, the translation sets both $A_t$
and $A_f$, or $A_a$, back to false for send and receive, respectively (this
occurs in $R$), thus causing the probe to evaluate to false again. This shows
that the probe evaluates to true strictly when the corresponding action is being
evaluated: the variables it depends on are set to true only during the
evaluation.

\section{Equivalences under the LTS}
% Stephen

 
\subsection{Strong Bisimulation}

Strong bisimulation is the strongest form of equivalence that we will discuss.
For two programs to be strongly bisimilar means that they must both be able to
simulate each other's labeled and unlabeled transitions. As this cannot allow
for any new communication actions or new internal actions, the amount of
parallelism that can be added is limited.

\subsubsection{Selection Weakening}

In the CHP language, there are two kinds of selection statement: one which
requires the designer to guarantee that all of the guard statements are
mutually exclusive, and one which does not. They are, respectively, the
deterministic and non-deterministic selection statements. In both cases, if
none of the guards are true (and it is not a repetitive selection statement),
they will block. In the case of a repeated selection statement, if none of the
guards are true, the program will skip over the statement. This behavior
allows repeated selection statements to eventually terminate.

The only difference between the two is that in the event that more than one
guard is true, the nondeterministic selection statement will choose one of them
arbitrarily.  Therefore, it is always the case that a deterministic selection
statement can be replaced with a nondeterministic selection statement without
altering the set of possible transitions.

For example, the CHP program:
\begin{align*}
&*[(C?c || D?d); \\
& \;\;\;\;\;[ c \rightarrow A!d \\
& \;\;\;\;\;\talloblong \lnot c \rightarrow B!d \\
& \;\;\;]] \\
\end{align*}
Can be replaced by:
\begin{align*}
&*[(C?c || D?d); \\
& \;\;\;\;\;[ c \rightarrow A!d \\
& \;\;\;\;\;| \lnot c \rightarrow B!d \\
& \;\;\;]] \\
\end{align*}
Without altering the set of transitions because the selection is deterministic,
and therefore, these two programs are bisimilar.

This transformation is somewhat impractical, as a nondeterministic selection
statement corresponds to additional circuit elements when synthesized.

\subsection{Weak Bisimulation}

Weak bisimulation is a form of bisimulation where only the labeled transitions
are considered.

\subsubsection{Process Decomposition}

Process decomposition is a common parallelism-increasing CHP transformation.  In
general, it involves taking programs of the form:

\[
...;S;...
\]

And decomposing them into ones of the form:

\[
(...;C;...) || *[[\overline{C} \rightarrow S; C]]
\]

Where C is a dataless channel action on a fresh channel (directionality has been
omitted, as dataless sends and receives are symmetric modulo variable renaming).

This transformation will only add a single $\tau$ action, as the channel C has
been explicitly declared to be fresh.  However, this transformation will not
add any additional parallelism, as all of the sequencing will be preserved. If
$S$ cannot perform any channel actions, then we can make an additional
transformation:

\[
(...;C;...) || *[[\bar{C} \rightarrow C; S]]
\]

And now we have increased parallelism, as the statements in $S$ have been
removed from the sequential execution path, and placed on a parallel one.

To avoid shared variables, it may be the case that several statements must be
decomposed at once, such as in:

\[
*[S_1; x := x + 1; S_2; [ c \rightarrow x := 0 \talloblong \lnot c \rightarrow \texttt{skip} ]; S_3; A!x ] 
\]

If none of $S_1$, $S_2$ and $S_3$ contain any actions on $x$, we can
move all of the actions on $x$ into a separate process resulting in:

\begin{align*}
& *[S_1; I; S_2; [ c \rightarrow J \talloblong \lnot c \rightarrow \texttt{skip} ]; S_3; K] \\
& || *[[\;\bar{I} \rightarrow x := x + 1; I \\
&\;\;\;\;\;\;\talloblong \bar{J} \rightarrow x := 0; J \\
&\;\;\;\;\;\;\talloblong \bar{K} \rightarrow  A!x; K \\
&]]
\end{align*}

Again, $I$, $J$, and $K$ are dataless channel actions, so directionality has
been omitted. This process can be re-ordered into:

\begin{align*}
& *[S_1; I; S_2; [ c \rightarrow J \talloblong \lnot c \rightarrow \texttt{skip} ]; S_3; K] \\
& || *[[\;\bar{I} \rightarrow I; x := x + 1 \\
&\;\;\;\;\;\;\talloblong \bar{J} \rightarrow J; x := 0 \\
&\;\;\;\;\;\;\talloblong \bar{K} \rightarrow  A!x; K \\
&]]
\end{align*}

As both of these systems only have one externally-visible channel action (on
$A$), their labeled transition systems will be the same modulo additional $\tau$
transitions from the $I$, $J$, and $K$ internal channel actions. Note that we do
need to know that $x$ does not occur in $S_1$, $S_2$ or $S_3$ for this to hold,
as $c$ must not have any dependencies on $x$. However, given that all of these
conditions hold, this final process will weakly bisimulate the original process.

\end{document}
