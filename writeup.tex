\documentclass[times, 10pt]{article}

\usepackage{amsmath}
\usepackage{mathpartir}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{stmaryrd}
\usepackage{cite}
\usepackage{verbatim}

\newcommand{\union}{\cup}
\newcommand{\Union}{\bigcup}
\newcommand{\intersection}{\cap}
\newcommand{\thickbar}{\talloblong}
%\newcommand{\Skip}{\hbox{\bf skip}}

\def\Skip{\hbox{\tt skip}}
\def\Else{\hbox{\bf else}}
\def\mod{\hbox{\bf mod}}
\def\true{\hbox{\bf true}}
\def\false{\hbox{\bf false}}
\let\prsarrow = \mapsto
\def\citepunct{,}  
\def\citedash{-}

\begin{document}

\title{Formalizing Communicating Hardware Processes}
\author{Stephen Longfield\\Alec Story\\Norris Xu}
\maketitle

\section{Introduction and Overview}
% Stephen

In this project, we apply conventional PL theory reasoning to the Communicating
Hardware Processes (CHP) language used by the Asynchronous VLSI group at
Cornell. 

Our first observation was that the CHP language is compiled down to the
handshaking expansion (HSE) language as the first step of the compilation
process, and HSE has far fewer primitives.  Therefore, we defined each construct
in CHP as being built from HSE primitives, and then reasoned about these simpler
structures.

While doing so, we observed that there were several programs that were
expressible in the CHP language, but not implementable in the HSE language, or
not implementable in the final hardware synthesis. We created programs to run
the static analyses to detect these unimplementable programs.

Additionally, we wanted to reason about programs in the CHP language in a way
consistent with the other concurrent process calculi.  Therefore, we built a
labeled transition system in the CHP language, and discussed how it related to
the HSE operational semantics that we had defined.  Once we had defined the LTS
semantics, we were able to use it to reason about simple equivalences.

\section{Asynchronous Computing}

Most modern computation is done using a synchronous methodology, where there is
a global clock that is used to synchronize between different computational
units.  Each computational unit guarantees that its signals will be valid and
ready to be used by the next stage by the end of the clock period, though they
need not make any guarantees about the signal before that point.  At the end of
each clock period, the signals are stored in state-holding elements to be used
for the next period of computation. 

In designing these circuits, a designer must take care that no computation ever
takes longer than the clock period to complete. Because this relies on
transistor timing simulation to determine, it is difficult to verify formally,
and may depend on things such as variations in temperature or manufacturing
process.

Alternatively, there exist several classes of asynchronous circuits, which do
not have the same clocking behavior, instead having the all of the
synchronization performed locally. These circuits have the advantages of
granting average case performance, and being easier to formally verify. In this
document, we will be focusing on the \emph{Quasi Delay Insensitive} (QDI) class
of asynchronous circuits, commonly viewed to be the ``most asynchronous'' class,
which makes the fewest assumptions about the underlying hardware.

One requirement of circuit behaviors that makes designing asynchronous hardware
more challenging is the fact that synchronization is done locally, and therefore
done with locally generated signals. For this synchronization to happen
correctly, these signals must not have glitches --- signals which appear to
transition, but in actuality do not. One way to guarantee this is to be certain
that any transition that can occur will eventually occur, forcing the system to
be strongly confluent.

A methodology which guarantees this property for QDI asynchronous circuits is
Alain Martin's synthesis method.  In this process, you begin with a high-level
description of the desired system in the \emph{Communicating Hardware Processes}
language, a derivative of Hoare's CSP, and make parallelism-increasing
transformations to turn it into a massively parallel system. This system is then
projected down onto only actions on Boolean shared variables, through the
process known as \emph{handshaking expansion}, which can then be further
translated into a CMOS-implementable circuit, but that transformation is outside
the scope of this paper.  We only target the shared-variable language.

This semantics of this synthesis process were described in Marcel Ren\'{e} van der
Goot's 1995 Phd thesis "Semantics of VLSI Synthesis", but were done in a
trace-theory based operational semantics significantly different from what is in
use in contemporary PL research, making it difficult to translate techniques
from current research into this field. Some methods for reasoning about the
compilation process have been proposed, such as Manohar's \emph{Behaviors},
introduced in the paper ``Slack Elasticity in Concurrent Computing'', but those
were again trace-based.

\section{CHP}
% Stephen

The Communicating Hardware Processes (CHP) language is the language commonly
used to describe asynchronous circuits at a high level.  A formal semantics will
be given for it in this document, but it is presented here informally.

As convention, variables are ranged over by lowercase letters, $a, b, c \ldots$,
channels are ranged over by uppercase letters from the beginning of the
alphabet, $A, B, C \ldots$ ,  and programs or program segments are ranged over
by uppercase letters from the second half of the alphabet, $P, Q, R \ldots$.
When we violate this convention, it will be explicitly mentioned.

\begin{itemize}

\item \textbf{Skip}: $\Skip$.  This statement does nothing.

\item \textbf{Assignment}: $x := \mathrm{b}$, where $\mathrm{b}$ is some Boolean
expression.  This statement means ``assign the value of $\mathrm{b}$ to $x$.'' The
statements $x\uparrow$ and $x\downarrow$ are shorthand for $x := \true$ and $x
:= \false$, respectively.

\item \textbf{Communication}: $A!\mathrm{b}$ is a statement meaning ``send the
value of $\mathrm{b}$ over channel $A$,'' and $B?x$ means ``receive a value over
channel $B$ and store it in variable $x$.''  Both sending and receiving are
blocking.

\item \textbf{Probe}: The Boolean $\overline{A}$ is true if and only if a
communication on channel $A$ can complete without suspending.  In our
formulation, we write $\overline{A!}$ to mean that the channel is trying to
send, and $\overline{A?}$ to mean that the channel is trying to receive, so the
opposite action can complete without suspending.  Note that this does not
guarantee that another program will not communicate with the channel and
invalidate the result of the probe, unless the probing program has exclusive
control over its end of the channel (which we have a mechanism to enforce).

\item \textbf{Selection}: $[G_1 \rightarrow P_1 \talloblong ... \talloblong G_n
\rightarrow P_n]$, where each $G_i$ is a Boolean expression, and each $P_i$ is a
statement.  This statement is executed by waiting for one of the guards to be
true, and then executing one statement with a true guard.  If the guards are not
mutually exclusive, we use the thin bar ($|$) instead of the thick bar
($\talloblong$). $[G]$ is used as a shorthand for $[G \rightarrow \Skip]$.

\item \textbf{Repetition}: $*[G_1 \rightarrow P_1 \talloblong ... \talloblong
G_n \rightarrow P_n]$. This statement is executed by choosing one of the true
guards and executing the corresponding statement, repeating until all guards
evaluate to false. If the guards are not mutually exclusive, we use the thin bar
($|$) instead of the thick bar ($\talloblong$). $*[P]$ is used as a shorthand for
$*[\true \rightarrow P]$.

\item \textbf{Sequential Composition}: $P;Q$.  This statement means ``execute
statement $P$, and then execute statement $Q$.''

\item \textbf{Parallel Composition}: $P || Q$.  This statement means ``execute
statement $P$ while simultaneously executing statement $Q$.''

\item \textbf{Simultaneous Composition}: $P \bullet Q$.  This statement means
``execute channel actions $P$ and $Q$ such that they complete simultaneously.'' 

\end{itemize}

\section{HSE}
% Alec

The CHP that existing users expect has too many primitives to model cleanly,
having both implicitly shared variables and channels. These channels are
complex, supporting multi-channel synchronization and peeking at channel state.
Rather than model the whole of CHP directly, we model a HSE which contains only
the shared variables and selection statements from CHP.  For the purposes of
this paper, HSE refers to conventional HSE plus arbitrary state disambiguation;
conventional HSE requires explicit variables to track state, but we do not model
those.

\subsection{Grammar}
\begin{align*}
\mathrm{\ell} & :: = \top \; | \; \bot \\
\mathrm{b} & ::= \ell \; | \;  a \; | \;
                 \mathrm{b}_1 \wedge \mathrm{b}_2 \; | \;
                 \mathrm{b}_1 \vee \mathrm{b}_2 \; | \;
                 \lnot \mathrm{b} \\
\mathrm{P} & ::= a := \mathrm{b} \; | \; S \; | \; *S \; | \;
                 P_1; P_2 \; | \: P_1 || P_2 \; | \;
                 \mathtt{\Skip} \\
\mathrm{S} & ::=
    [ \mathrm{b}_1 \rightarrow P_1  \talloblong \; ... \;
      \talloblong \mathrm{b}_n \rightarrow P_n ] \; | \;
    [ \mathrm{b}_1 \rightarrow P_1 | \; ... \; | \mathrm{b}_n \rightarrow P_n ]
\end{align*}

\subsection{Operational Semantics}
\subsubsection{Booleans}

\begin{mathpar}
\inferrule* [left=Primitive]
    { }
    {\sigma \models \ell = \ell}

\inferrule* [left=Read]
    {[a = \ell] \in \sigma}
    {\sigma \models a = \ell}

\inferrule* [left=Neg]
    {\sigma \models \mathrm{b} = \ell}
    {\sigma \models \lnot \mathrm{b} = \lnot \ell}

\inferrule* [left=And]
    {\sigma \models \mathrm{b}_1 = \ell_1 \\
     \sigma \models \mathrm{b}_2 = \ell_2}
    {\sigma \models \mathrm{b}_1 \land \mathrm{b}_2 = \ell_1 \land \ell_2}

\inferrule* [left=Or]
    {\sigma \models \mathrm{b}_1 = \ell_1 \\ \sigma \models \mathrm{b}_2 = \ell_2}
    {\sigma \models \mathrm{b}_1 \lor \mathrm{b}_2 = \ell_1 \lor \ell_2}
\end{mathpar}

Behavior of a Boolean statement containing an uninitialized variable is
undefined.

\subsubsection{Processes}

\begin{mathpar}

\inferrule* [left=SkipSeq]
    { }
    {\Skip; P, \sigma \rightarrow P, \sigma}

\inferrule* [left=SkipPar]
    { }
    {\Skip || P, \sigma \rightarrow P, \sigma}

\inferrule* [left=ParCommute]
    { }
    {P_1 || P_2, \sigma \rightarrow P_2 || P_1, \sigma}
\end{mathpar}

\begin{mathpar}
\inferrule* [left=StepSeq]
    {P_1, \sigma \rightarrow P_1', \sigma'}
    {P_1; P_2, \sigma \rightarrow P_1'; P_2, \sigma'}

\inferrule* [left=StepPar]
    {P_1, \sigma \rightarrow P_1', \sigma'}
    {P_1 || P_2, \sigma \rightarrow P_1' || P_2, \sigma'}

\inferrule* [left=Assign]
    {\sigma \models \mathrm{b} = \ell}
    {a := \mathrm{b}, \sigma \rightarrow \Skip, \sigma[ a = \ell]}
\end{mathpar}

\begin{mathpar}
\inferrule* [left=SelectDet]
    {\sigma \models \mathrm{b}_1 = \bot \land \ldots \land
                    \mathrm{b}_{i-1} = \bot \land
                    \mathrm{b}_i = \top \land
                    \mathrm{b}_{i+1} = \bot \land \ldots \land
                    \mathrm{b}_n = \bot}
    {[\mathrm{b}_1 \rightarrow P_1 \thickbar \ldots \thickbar
      \mathrm{b}_i \rightarrow P_i \thickbar \ldots \thickbar
      \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow P_i, \sigma}

\inferrule* [left=SelectNonDet]
    {\sigma \models \mathrm{b}_i = \top}
    {[\mathrm{b}_1 \rightarrow P_1 | \ldots |
      \mathrm{b}_i \rightarrow P_i | \ldots |
      \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow P_i, \sigma}
\end{mathpar}

\begin{mathpar}
\inferrule* [left=Repeat]
    {S, \sigma \rightarrow P, \sigma}
    {*S, \sigma \rightarrow P; *S, \sigma}

\inferrule* [left=RepeatNoneDet]
    {\sigma \models \mathrm{b}_1 = \bot \land \ldots \land \mathrm{b}_n = \bot}
    {*[\mathrm{b}_1 \rightarrow P_1 \thickbar \ldots \thickbar
      \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow \Skip, \sigma}

\inferrule* [left=RepeatNoneNonDet]
    {\sigma \models \mathrm{b}_1 = \bot \land \ldots \land \mathrm{b}_n = \bot}
    {*[\mathrm{b}_1 \rightarrow P_1 | \ldots |
       \mathrm{b}_n \rightarrow P_n], \sigma \rightarrow \Skip, \sigma}
\end{mathpar}


\section{CHP embedding into HSE}
% Norris/Stephen

\begin{comment}
\subsection{HSE Grammar}
\begin{align*}
    \ell & ::= \top \; | \bot \\
    \mathrm{b} & ::= a \; | \; \ell \; | \; \mathrm{b}_1 \wedge \mathrm{b}_2 \; | \; \mathrm{b}_1 \vee \mathrm{b}_2 \; | \; \lnot \mathrm{b} \\
    \mathrm{P} & ::= a := \mathrm{b} \; | \; S \; | \, *S \; | \; P_1; P_2 \; | \: P_1 || P_2 \; | \; \mathtt{skip} \\
    \mathrm{S} & ::= [ \mathrm{b}_1 \rightarrow P_1 \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] \; | \; [ \mathrm{b}_1 \rightarrow P_1 | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] \\
\end{align*}

\end{comment}


\subsection{CHP Grammar}
\begin{align*}
    \ell & ::= \top \; | \bot \\
    \mathrm{b} & ::= a \; | \; \ell \; | \; \overline{A!} \; | \; \overline{A?} \; | \; \mathrm{b}_1 \wedge \mathrm{b}_2 \; | \; \mathrm{b}_1 \vee \mathrm{b}_2 \; | \; \lnot \mathrm{b} \\
    \mathrm{P} & ::= a := \mathrm{b} \; | \; S \; | \, *S \; | \; C \; | \; P_1; P_2 \; | \: P_1 || P_2 \; | \; \mathtt{skip} \\
    \mathrm{S} & ::= [ \mathrm{b}_1 \rightarrow P_1 \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] \; | \; [ \mathrm{b}_1 \rightarrow P_1 | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] \\
    \mathrm{C} & ::= A!\mathrm{b} \; | \; A?a \; | \; C_1 \bullet C_2
\end{align*}

The only terms appearing in this grammar but not the HSE grammar are:
$\overline{A!}$, $\overline{A?}$, $A!\mathrm{b}$, $A?a$, and $C_1 \bullet C_2$.
It suffices to give translations for just these extra terms;
everything else translates to its equivalent in HSE. We also need to pick an
active end and a passive end for each channel in order to translate into HSE.
We decide which end of the channel (the sending end or the receiving end) should
be active using the static analysis below, and denote by $\rho \vDash A!$ the
channel $A$ having its sending end active, and $\rho \vDash A?$ the channel $A$
having its receiving end active.  For simplicity, we restrict all channels to be
Boolean channels.

Note that the fire prevention static analysis (described below) allows us to assume that all
channels are end-to-end.

The chanel actions are encoded onto a set of three boolean variables: $A_a$ for
channel acknowledge, and $A_t$ and $A_f$ for channel data.

\subsection{Translation}

We use $\{C\}$ as shorthand to indicate terms which are translations of channel
actions in CHP.

\begin{align*}
    \overline{A!} & \Rightarrow (A_t \vee A_f) \\
    \overline{A?} & \Rightarrow A_a \\
    A!\mathrm{b} & \Rightarrow \left\{ \begin{matrix} [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [A_a]; A_t := \bot; A_f := \bot; [\neg A_a] & \qquad \rho \vDash A! \\
                                                      [A_a]; [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [\neg A_a]; A_t := \bot; A_f := \bot & \qquad \rho \vDash A? \end{matrix} \right. \\
    A?a & \Rightarrow \left\{ \begin{matrix} [A_t \vee A_f]; a := A_t; A_a := \top; [\neg A_t \wedge \neg A_f]; A_a := \bot & \qquad \rho \vDash A! \\
                                             A_a := \top; [A_t \vee A_f]; a := A_t; A_a := \bot; [\neg A_t \wedge \neg A_f] & \qquad \rho \vDash A? \end{matrix} \right. \\
     %%% Bulleted receive, both passive
    C_1?a \bullet C_2?a & \Rightarrow \left\{ \begin{matrix} (([C_{1_t} \vee C_{1_f}]; a := C_{1_t}; C_{1_a} := \top) || ([C_{2_t} \vee C_{2_f}]; a := C_{2_t}; C_{2_a} := \top)); 
    \\ [\neg C_{1_t} \wedge \neg C_{1_f} \wedge \neg C_{2_t} \wedge \neg C_{2_f}]; (C_{1_a} := \bot\ ||C_{2_a} := \bot\ ) & \qquad \rho \vDash C_1!, C_2! \\
    %%% Bulleted receive, one active
    (([C_{1_t} \vee C_{1_f}]; a := C_{1_t}; C_{1_a} := \top) || ([C_{2_t} \vee C_{2_f}]; a := C_{2_t}; C_{2_a} := \top)); 
    \\ [\neg C_{1_t} \wedge \neg C_{1_f}];  C_{2_a} := \bot; [ \neg C_{2_t} \wedge \neg C_{2_f}]; C_{1_a} := \bot\ & \qquad \rho \vDash C_1!, C_2?
      \end{matrix} \right.  \\
      %%% Bulleted send, both passive
          C_1!\mathrm{b}_1 \bullet C_2!\mathrm{b}_2 & \Rightarrow \left\{ \begin{matrix} (([C_{1_a}]; [\mathrm{b}_1 \rightarrow C_{1_t} := \top \talloblong \neg \mathrm{b}_1 \rightarrow C_{1_f} := \top]) || \\ ([C_{2_a}]; [\mathrm{b}_2 \rightarrow C_{2_t} := \top \talloblong \neg \mathrm{b}_2 \rightarrow C_{2_f} := \top])); 
    \\ [\neg C_{1_a} \wedge \neg C_{2_a}]; (C_{1_t} := \bot\ || C_{1_f} := \bot\ || C_{2_t} := \bot\ || C_{2_f} := \bot\ ) & \; \rho \vDash C_1?, C_2? \\
    %%% Bulleted send, one active
    (([C_{1_a}]; [\mathrm{b}_1 \rightarrow C_{1_t} := \top \talloblong \neg \mathrm{b}_1 \rightarrow C_{1_f} := \top]) || \\ ([\mathrm{b}_2 \rightarrow C_{2_t} := \top \talloblong \neg \mathrm{b}_2 \rightarrow C_{2_f} := \top]; [C_{2_a}])); 
    \\ [\neg C_{1_a}]; ( C_{2_t} := \bot\ || C_{2_f} := \bot\ );  [\neg C_{2_a}];  (C_{1_t} := \bot\ || C_{1_f} := \bot\ ) & \; \rho \vDash C_1?, C_2!
      \end{matrix} \right. \\
      %%% Bulleted send/recieve, both passive
          C_1!\mathrm{b} \bullet C_2?a & \Rightarrow \left\{ \begin{matrix} (([C_{1_a}]; [\mathrm{b}_1 \rightarrow C_{1_t} := \top \talloblong \neg \mathrm{b}_1 \rightarrow C_{1_f} := \top]) || ([C_{2_t} \vee C_{2_f}]; a := C_{2_t}; C_{2_a} := \top)); 
    \\ [\neg C_{1_a} \wedge \neg C_{2_t} \wedge \neg C_{2_f}]; (C_{1_t} := \bot\ || C_{1_f} := \bot\ ||C_{2_a} := \bot\ ) & \qquad \rho \vDash C_1!, C_2! \\
    %%% Bulleted send/recieve, receive active
         (([C_{1_a}]; [\mathrm{b}_1 \rightarrow C_{1_t} := \top \talloblong \neg \mathrm{b}_1 \rightarrow C_{1_f} := \top]) || C_{2_a} := \top; (C_{2_t} \vee C_{2_f}]; a := C_{2_t})); 
    \\ [\neg C_{1_a}]; C_{2_a} := \bot\ ; [ \neg C_{2_t} \wedge \neg C_{2_f}]; (C_{1_t} := \bot\ || C_{1_f} := \bot\ ) & \qquad \rho \vDash C_1!, C_2? \\
    %%% Builleted send/recieve, send active
      (( [\mathrm{b}_1 \rightarrow C_{1_t} := \top \talloblong \neg \mathrm{b}_1 \rightarrow C_{1_f} := \top];  [C_{1_a}] ) || ([C_{2_t} \vee C_{2_f}]; a := C_{2_t}; C_{2_a} := \top)); 
    \\ [\neg C_{2_t} \wedge \neg C_{2_f}]; (C_{1_t} := \bot\ || C_{1_f} := \bot\ ); [\neg C_{1_a}]; C_{2_a} := \bot\ & \qquad \rho \vDash C_1?, C_2!
      \end{matrix} \right. 
\end{align*}

\section{Restrictions and Static Analysis}
%Alec

\subsection{Concurrent Write Prevention}

When our language is implemented on hardware, if we ever have two concurrent
programs writing two different values to the same variable simultaneously,
voltage connects to ground through the variable --- a short circuit --- and may
literally cause the circuit to catch fire.  To prevent this from happening, we
provide a static analysis method that tracks which variables a program may write
to, and prohibits potentially parallel processes from writing to the same
variables.  Because HSE is Turing-complete modulo infinite memory, we take a
worst-case evaluation of select statements.

This is accomplished by simple tree traversal over the AST.  Writes to variables
only occur in three places:

\begin{description}
\item[Variable Assignment:] The variable being written to.
\item[Channel Sends:] The data variables of the channel
\item[Channel Receives:] The acknowledge variable of the channel, and the
variable that we store the result into.
\end{description}

By traversing a program and accumulating the variables written, we can generate
a set of variables that that program may write to.  With this ability, we just
need to check whether these variable sets intersect when we introduce
parallelism.

The first and most obvious cases is across the parallel composition operator
$||$.  If a variable may be written to on both sides of the operator, we have a
potential fire.

More subtly, the bullet combinator for channel actions also introduces
parallelism (and, indeed, when we compile to HSE, it compiles into parallel
composition), and may cause fires.  For example, consider $A?x \bullet B?x$.
This may write conflicting values to the variable x simultaneously, and cause a
fire.  Traversing all the components of a bullet and building the variable sets
as we do for parallel composition prevents this from occurring.

One desirable side-effect of this restriction is that it forces all channels to
only have two concurrent endpoints at any time (they are \emph{end-to-end}):  if
two separate parallel processes could write to or read from the same channel,
there would be a potential fire on that channel's data or acknowledge variables.
This restriction ensures that the channels of CHP are easy to implement in
hardware --- while multi-endpoint channels are possible, they are very complex,
and require a lot of assumptions about the behavior of the corresponding
programs to function correctly, and the same functionality could be achieved by
just having a process mediate between the channels.  Note that this restriction
does not apply to probes, since they are strictly read only.

Additionally, we could have had the fire detection run post-translation into
HSE.  Any fire that occurs in CHP will also occur post-translation, and as it
stands, fire detection has to understand the basics of transforming channels
into variables. As fire detection places limits on the complexity of the
programs described (end-to-end channels for example), requiring that a program
be fire-free makes translation simpler.  For example, deriving correct bullet
transformations with possibly non-end-to-end channels would be extremely
difficult.

\subsection{A Type System for Channel Directionality}

When channels are implemented via transformation into variable reads and sets
using a handshake, one end of the channel waits first, and one end of the
channel writes first.  Either the sender or receiver can act first; a channel is
\emph{active} if the sender acts first, and \emph{passive} if the receiver acts
first.  We define the \emph{active end} of a channel as the end of the channel
that moves first; this is the sender for active channels and the receiver for
passive channels. We refer to this property of channels as \emph{directionality}.

Before we can transform CHP channels into HSE variables, we need to determine
the directionality of all the channel.  If there are no other restrictions on
channels, they can be assigned a directionality arbitrarily.  However, probes
and bullets place restrictions on the directionality of channels:

A probe can only probe the active end of a channel, because it listens for the
beginning of a channel action, and a wait is done silently, and cannot be
detected without interfering with the channel.

Bullets require that at most one of the channel ends in the bullet may be
active.  This requirement comes, too, from the implementation:  bullets must act
simultaneously, and HSE (and QDI circuits) provides a mechanism for synchronous
waiting, but not for synchronous writing to variables.

The bullet requirement can become difficult to solve since many bullets may be
entangled through channels that they share.  Fortunately, we can reduce this
problem to 2-SAT, where each channel is mapped to a variable of the same name,
and if that variable is true, then the channel is active:
\begin{align*}
\overline{A!} & \mapsto (A \lor A) \\
\overline{A?} & \mapsto (\lnot A \lor \lnot A) \\
A! \bullet B! & \mapsto (\lnot A \lor \lnot B) \\
A! \bullet B? & \mapsto (\lnot A \lor B) \\
A? \bullet B? & \mapsto (A \lor B)
\end{align*}

If we apply these rules to build up a set of restrictions from each probe and
each pair of channel actions that share a bullet in the program, any variable
assignment that satisfies them will ensure that the above constraints are
satisfied.

We have implemented a 2-SAT solver using the Aspvall, Plass \& Tarjan strongly
connected component algorithm; it runs in quadratic time on the size of bullets
(since we have a rule for each pair), and otherwise linear time on the number of
probes and bullets.  For channels whose directionality is unrestricted, it
assigns the direction arbitrarily.

\section{Labeled Transition System for CHP}
% Norris
We begin by defining a ternary relation and a function. First, we define
$\mathsf{match} \subseteq \mathbf{Labels} \times \mathbf{Labels} \times
\mathbf{Assignments}$ (where labels is the set of possible labels on
transitions, which can either be tau or a set of channel communications, and
assignments is a set of assignments of values to variables) as follows:
$$
    \frac{A \in \mathbf{Channels} \quad a \in \mathbf{Variables}}{(\{A!\ell\}, \{A?a : \ell\}, \{[a = \ell]\}) \in \mathsf{match}} \qquad
    \frac{(\delta, \delta', \Sigma) \in \mathsf{match}}{(\delta', \delta, \Sigma) \in \mathsf{match}} $$$$
    \frac{(\delta, \delta', \Sigma) \in \mathsf{match}}{(\delta \cup \{A!\ell\}, \delta' \cup \{A?a : \ell\}, \Sigma \cup \{[a = \ell\}) \in \mathsf{match}}
$$
Intuitively, $(\delta, \delta', \Sigma) \in \mathsf{match}$ means that the set
of communications in label $\delta$ is the complement (i.e. sends correspond
bijectively to receives) of communications in $\delta'$, and $\Sigma$ is the set
of assignments that occur as a result of carrying out those communications (i.e.
$a := \top \in \Sigma$ if and only if there is some channel receive writing
$\top$ into $a$ in either $\delta$ or $\delta'$).

Next, we define $\mathsf{head}: \mathbf{Programs} \rightarrow
2^{\mathbf{ChannelActions}}$ (where ChannelActions = ${A!, A?}$)as follows:
\begin{flalign*}
    \mathsf{head}(P || Q) & = \mathsf{head}(P) \cup \mathsf{head}(Q) \\
    \mathsf{head}(P ; Q) & = \mathsf{head}(P) \\
    \mathsf{head}(A!\ell) & = \{A!\} \\
    \mathsf{head}(A?a) & = \{A?\} \\
    \mathsf{head}(A!\ell \bullet C) & = \{A!\} \cup \mathsf{head}(C) \\
    \mathsf{head}(A?a \bullet C) & = \{A?\} \cup \mathsf{head}(C) \\
    \mathsf{head}(P) & = \varnothing \quad \text{for any other program $P$}
\end{flalign*}
Intuitively, $\mathsf{head}(P)$ returns the set of all chanel actions that are
currently executing.

We start with the Boolean reduction rules. Here, $P, \sigma$ are the enclosing
program $P$ and the current environment $\sigma$, respectively.
$$
    \frac{}{P, \sigma \models \ell = \ell} \qquad
    \frac{[a = \ell] \in \sigma}{P, \sigma \models a = \ell} \qquad
    \frac{P, \sigma \models \mathrm{b} = \ell}{P, \sigma \models \neg \mathrm{b} = \neg \ell} $$$$
    \frac{P, \sigma \models \mathrm{b} = \top}{P, \sigma \models \mathrm{b} \vee \mathrm{b}' = \top} \qquad
    \frac{P, \sigma \models \mathrm{b}' = \top}{P, \sigma \models \mathrm{b} \vee \mathrm{b}' = \top} \qquad
    \frac{P, \sigma \models \mathrm{b} = \bot \quad P, \sigma \models \mathrm{b}' = \bot}{P, \sigma \models \mathrm{b} \vee \mathrm{b}' = \bot} $$$$
    \frac{P, \sigma \models \mathrm{b} = \bot}{P, \sigma \models \mathrm{b} \wedge \mathrm{b}' = \bot} \qquad
    \frac{P, \sigma \models \mathrm{b}' = \bot}{P, \sigma \models \mathrm{b} \wedge \mathrm{b}' = \bot} \qquad
    \frac{P, \sigma \models \mathrm{b} = \top \quad P, \sigma \models \mathrm{b}' = \top}{P, \sigma \models \mathrm{b} \wedge \mathrm{b}' = \top} $$$$
    \frac{A! \in \mathsf{head}(P)}{P, \sigma \models \overline{A!} = \top} \qquad
    \frac{A! \notin \mathsf{head}(P)}{P, \sigma \models \overline{A!} = \bot} \qquad
    \frac{A? \in \mathsf{head}(P)}{P, \sigma \models \overline{A?} = \top} \qquad
    \frac{A? \notin \mathsf{head}(P)}{P, \sigma \models \overline{A?} = \bot}
$$

%Here are the rules for CHP:
Continuing with the rules for statements in CHP (we use $\sigma \models$ as
shorthand for $P, \sigma \models$ to avoid having to include the entire text of
the program):

$$
    % skip, assign, sequential and parallel composition rules
    \frac{\langle P, \sigma \rangle \xrightarrow{\delta} \langle P', \sigma' \rangle}{\langle P ; Q, \sigma \rangle \xrightarrow{\delta} \langle P' ; Q, \sigma' \rangle} \qquad
    \frac{\langle P, \sigma \rangle \xrightarrow{\delta} \langle P', \sigma' \rangle}{\langle P || Q, \sigma \rangle \xrightarrow{\delta} \langle P' || Q, \sigma' \rangle} \qquad
    \frac{\langle Q, \sigma \rangle \xrightarrow{\delta} \langle Q', \sigma' \rangle}{\langle P || Q, \sigma \rangle \xrightarrow{\delta} \langle P || Q', \sigma' \rangle} \qquad
    \frac{}{\langle \mathtt{skip}; P, \sigma \rangle \xrightarrow{\tau} \langle P, \sigma \rangle} $$$$
    \frac{\sigma \models \mathrm{b} = \ell}{\langle a := \mathrm{b}, \sigma \rangle \xrightarrow{\tau} \langle \mathtt{skip}, \sigma[a = \ell] \rangle} \qquad
    \frac{}{\langle \mathtt{skip} || P, \sigma \rangle \xrightarrow{\tau} \langle P, \sigma \rangle} \qquad
    \frac{}{\langle P || \mathtt{skip}, \sigma \rangle \xrightarrow{\tau} \langle P, \sigma \rangle} $$$$
    % selection rules
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_{i-1} = \bot \; \wedge \mathrm{b}_i = \top \wedge \mathrm{b}_{i+1} = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_n = \bot} {\langle [ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i , \sigma\rangle  } \qquad
    \frac{\sigma \models \mathrm{b}_i = \top} {\langle [ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i , \sigma\rangle  } $$$$
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \ldots \wedge \mathrm{b}_n = \bot}{\langle *[ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle \mathtt{skip} , \sigma\rangle } \qquad
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \ldots \wedge \mathrm{b}_n = \bot}{\langle *[ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle \mathtt{skip} , \sigma \rangle } $$$$
%   \frac{\langle S, \sigma \rangle \xrightarrow{\tau} \langle P, \sigma \rangle}{\langle *S, \sigma \rangle \xrightarrow{\tau} \langle P;*S, \sigma \rangle} $$$$
    \frac{\sigma \models \mathrm{b}_1 = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_{i-1} = \bot \wedge \mathrm{b}_i = \top \wedge \mathrm{b}_{i+1} = \bot \wedge \; \ldots \; \wedge \; \mathrm{b}_n = \bot} {\langle *[ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i; \; *[ \mathrm{b}_1 \rightarrow P_1  \talloblong \; \ldots \; \talloblong \mathrm{b}_n \rightarrow P_n ] , \sigma\rangle  } $$$$
    \frac{\sigma \models \mathrm{b}_i = \top} {\langle *[ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma \rangle \xrightarrow{\tau} \langle P_i;\;*[ \mathrm{b}_1 \rightarrow P_1  | \; \ldots \; | \mathrm{b}_n \rightarrow P_n ] , \sigma\rangle  } $$$$
    % communication rules
    \frac{\sigma \models \mathrm{b} = \top}{\langle \{A!\mathrm{b}\}, \sigma \rangle \xrightarrow{A!\top} \langle \mathtt{skip}, \sigma[A_t = \top, A_a = \top] \rangle} \qquad
    \frac{\sigma \models \mathrm{b} = \bot}{\langle \{A!\mathrm{b}\}, \sigma \rangle \xrightarrow{A!\bot} \langle \mathtt{skip}, \sigma[A_f = \top, A_a = \top] \rangle} $$$$
    \frac{}{\langle \{A?a\}, \sigma \rangle \xrightarrow{A?a : \top} \langle \mathtt{skip}, \sigma[A_t = \top, A_a = \top, a = \top] \rangle} \qquad
    \frac{}{\langle \{A?a\}, \sigma \rangle \xrightarrow{A?a : \bot} \langle \mathtt{skip}, \sigma[A_f = \top, A_a = \top, a = \bot] \rangle} $$$$
    %\frac{\langle P, \sigma \rangle \xrightarrow{A!\ell} \langle P', \sigma \rangle \quad \langle Q, \sigma' \rangle \xrightarrow{A?a : \ell} \langle Q', \sigma'' \rangle}{\langle P || Q, \sigma \rangle \xrightarrow{\tau} \langle P' || Q', \sigma[a = \ell] \rangle} $$$$
    %\frac{\langle P, \sigma \rangle \xrightarrow{A?a : \ell} \langle P', \sigma' \rangle \quad \langle Q, \sigma'' \rangle \xrightarrow{A!\ell} \langle Q', \sigma'' \rangle}{\langle P || Q, \sigma \rangle \xrightarrow{\tau} \langle P' || Q', \sigma[a = \ell] \rangle}
    \frac{\langle P, \sigma \rangle \xrightarrow{\delta} \langle P', \sigma' \rangle \quad \langle Q, \sigma'' \rangle \xrightarrow{\delta'} \langle Q', \sigma''' \rangle \quad (\delta, \delta', \Sigma) \in \mathsf{match}}{\langle P || Q, \sigma \rangle \xrightarrow{\tau} \langle P' || Q', \sigma[\Sigma] \rangle} $$$$
    % bullet rules
    \frac{\langle \{C\}, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle \quad \sigma \models \mathrm{b} = \top}{\langle \{A!\mathrm{b} \bullet C\}, \sigma \rangle \xrightarrow{\delta \cup \{A!\top\}} \langle \mathtt{skip}, \sigma'[A_t = \top, A_a = \top] \rangle} $$$$
    \frac{\langle \{C\}, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle \quad \sigma \models \mathrm{b} = \bot}{\langle \{A!\mathrm{b} \bullet C\}, \sigma \rangle \xrightarrow{\delta \cup \{A!\bot\}} \langle \mathtt{skip}, \sigma'[A_f = \top, A_a = \top] \rangle} $$$$
    \frac{\langle \{C\}, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle}{\langle \{A?a \bullet C\}, \sigma \rangle \xrightarrow{\delta \cup \{A?a : \top\}} \langle \mathtt{skip}, \sigma'[A_t = \top, A_a = \top, a = \top] \rangle} $$$$
    \frac{\langle \{C\}, \sigma \rangle \xrightarrow{\delta} \langle \mathtt{skip}, \sigma' \rangle}{\langle \{A?a \bullet C\}, \sigma \rangle \xrightarrow{\delta \cup \{A?a : \bot\}} \langle \mathtt{skip}, \sigma'[A_f = \top, A_a = \top, a = \top] \rangle} $$$$
$$

Where $\sigma$ is the environment, which in this case consists of a set of
mappings of variables to values.  We initialize $\sigma$ to include $A_a =
\bot$, $A_t = \bot$, $A_f = \bot$ for all channels $A$.  Furthermore, note that
the labels on the transitions are sets, since we can have several channel
operations occurring at once (via $\bullet$).

\section{LTS and HSE Equality}
% Norris

In the following, we construct a proof sketch showing that the transitions of
the LTS correspond to those of the HSE.

We begin our discussion of correspondence by noting that for anything aside from
probes and channel actions, since the transition rules are identical, it follows
that the behavior is also identical. Therefore, we will only be showing that the
translations of channel actions and probes correspond to the definition above.
Incidentally, due to the details of the hardware implementation, there are many
programs that appear valid in CHP, yet will not pass static analysis and thus
cannot be translated into HSE. We will discuss the correctness of the
translation only for programs that are both valid CHP and pass the static
analyses.

The translation of the two basic channel actions is the \emph{four-phase
handshake}, which works as follows: every channel has three variables assigned
to it. For a channel $A$, our translation rules name these as $A_a$, $A_t$, and
$A_f$. Initially (i.e. when no channel action is being performed), all three of
these variables are set to false. In addition, for each channel, we must pick
one of the ends to be the active end, and the other to be the passive end. Thus
there are two cases.

If the sending end of the channel is the passive end, then the four-phase
handshake proceeds as follows: the receiving end of the channel (the active end)
initiates the handshake by setting $A_a$ to be true.  It then waits for data to
be sent by checking for either $A_t$ or $A_f$ to be true.  The sending end (the
passive end) waits for the handshake to be initiated by checking for $A_a$ to be
true. It then initiates the send by setting either $A_t$ or $A_f$ to true,
depending on which value is to be sent. The receiving end, upon receiving the
data and setting $a$, indicates receipt by setting $A_a$ to be false; it then
waits for the sending end to acknowledge the end of the handshake by setting
both $A_t$ and $A_f$ to again (at which point all three variables will have
returned to their original, false states). The sending end, upon seeing the
acknowledgement of receipt, sets $A_t$ and $A_f$ to false again, ending
the handshake. This handshake enforces simultaneity: if a process attempts to
send without there being a receiver, then it will block until another process
attempts to receive and sets $A_a$ to true. If a process attempts to receive
without there being a sender, then it will set $A_a$ to true, but then block
until another process sends a value by setting either $A_t$ or $A_f$ to be true.
Finally, once the handshake is complete, $A_a$, $A_t$, and $A_f$ are all set to
false once more, resetting the channel in preparation for another channel
action.

The translations for the case where the sending end is passive (i.e. $\rho
\vDash A?$) are as follows:
\begin{flalign*}
    A!\mathrm{b} & \Rightarrow [A_a]; [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [\neg A_a]; A_t := \bot; A_f := \bot \\
    A?a & \Rightarrow A_a := \top; [A_t \vee A_f]; a := A_t; A_a := \bot; [\neg A_t \wedge \neg A_f]
\end{flalign*}

The translations for the case where the receiving end is passive (i.e. $\rho
\vDash A!$) are as follows:
\begin{flalign*}
    A!\mathrm{b} & \Rightarrow [\mathrm{b} \rightarrow A_t := \top \talloblong \neg \mathrm{b} \rightarrow A_f := \top]; [A_a]; A_t := \bot; A_f := \bot; [\neg A_a] \\
    A?a & \Rightarrow [A_t \vee A_f]; a := A_t; A_a := \top; [\neg A_t \wedge \neg A_f]; A_a := \bot
\end{flalign*}
In both cases, the translations exactly correspond to the description given
above. Thus, they are correct.

In the case of bullet, to keep things simple, we only look at dataless
channels. The channels can easily be extended to send and receive data by
replacing one or both of the channel communication variables with a set of
variables. Since we are only dealing with dataless channels, we will use $A$ to
indicate communication on a channel for either end (as the ends are now
equivalent); we also use $A_a$ and $A_b$ as the two communication variables for
$A$.

In order to enforce simultaneity, we must place some restrictions on the set of
channels in the bullet; to be specific, we can allow at most one channel in the
set to be active, and the rest must be passive. In the case of $n$ passive
channels $A_1, \ldots, A_n$, the translation for $A_1 \bullet \ldots \bullet
A_n$ is:
$$[{A_a}_1 \wedge \ldots \wedge {A_a}_n]; ( {A_b}_1 := \top || \ldots || {A_b}_n := \top); [\neg {A_a}_1 \wedge \ldots \wedge \neg {A_a}_n]; ( {A_b}_1 := \bot || \ldots || {A_b}_n := \bot)$$
In the case of one active channel $B$ and $n$ passive channels $A_1, \ldots,
A_n$, the translation for $A_1 \bullet \ldots \bullet A_i \bullet B \bullet
A_{i + 1} \bullet \ldots \bullet A_n$ is:

$$B_a := \top; [B_b \wedge {A_a}_1 \wedge \ldots \wedge {A_a}_n]; ({A_b}_1 := \top || \ldots || {A_b}_n := \top); [\neg {A_a}_1 \wedge \ldots \wedge \neg {A_a}_n]; B_a := \bot; [\neg B_b]; ({A_b}_1 := \bot || \ldots || {A_b}_n := \bot)$$

We will start with the first case, when all of the channels are passive.
Clearly, the translation implements the four-phase handshake: for each channel
$A_i$, we first wait for ${A_a}_i$ to go high, then we set ${A_b}_i$ to high and
wait for ${A_a}_i$ to go low, and finally we set ${A_b}_i$ to low. We also
perform the last step simultaneously for all channels, thus fitting the
definition of bullet.

For the second case, we complete all of the passive channel actions correctly
and simultaneously for the same reasons as in the first case. For channel $B$,
we again implement the four-phase handshake: we first set $B_a$ to high, then we
wait for $B_b$ to go high, then we set $B_a$ to low, and finally we wait for
$B_b$ to go low. We wait until $B_b$ is low before setting each of the ${A_b}_i$
to low, thus completing all channel actions simultaneously.

Next, we argue that the translations of the probes are correct. Due to
limitations of the hardware implementation, we can only ever probe the active
end of the channel, since the passive end makes no visible changes when it is
blocked on a channel action. Thus, for a channel with a passive receiving end,
the only probe allowed is a send probe ($\overline{A!}$); likewise, for a
channel with a passive sending end, the only probe allowed is a receive probe
($\overline{A?}$). Thus we only have one translation for each probe:
\begin{flalign*}
    \overline{A!} & \Rightarrow (A_t \vee A_f) \\
    \overline{A?} & \Rightarrow A_a \\
\end{flalign*}
The send probe will only ever be true at the very beginning of an active send:
when a process attempts to send (by setting $A_t$ or $A_f$ to true). Likewise,
the receive probe will only ever be true at the very beginning of an active
receive: when a process attempts to receive (by setting $A_a$ to true). This
behaviour corresponds to the definition of probe; thus, the translations are
correct in the cases where they apply.

\section{Equivalences under the LTS}
% Stephen

 
\subsection{Strong Bisimulation}

Strong bisimulation is the strongest form of equivalence that we will discuss.
For two programs to be strongly bisimilar means that they must both be able to
simulate each other's labeled and unlabeled transitions. As this cannot allow
for any new communication actions or new internal actions, the amount of
parallelism that can be added is limited.

\subsubsection{Selection Weakening}

In the CHP language, there are two kinds of selection statement: one which
requires the designer to guarantee that all of the guard statements are
mutually exclusive, and one which does not. They are, respectively, the
deterministic and non-deterministic selection statements. In both cases, if
none of the guards are true (and it is not a repetitive selection statement),
they will block. In the case of a repeated selection statement, if none of the
guards are true, the program will skip over the statement. This behavior
allows repeated selection statements to eventually terminate.

The only difference between the two is that in the event that more than one
guard is true, the nondeterministic selection statement will choose one of them
arbitrarily.  Therefore, it is always the case that a deterministic selection
statement can be replaced with a nondeterministic selection statement without
altering the set of possible transitions.

For example, the CHP program:
\begin{align*}
&*[(C?c || D?d); \\
& \;\;\;\;\;[ c \rightarrow A!d \\
& \;\;\;\;\;\talloblong \lnot c \rightarrow B!d \\
& \;\;\;]] \\
\end{align*}
Can be replaced by:
\begin{align*}
&*[(C?c || D?d); \\
& \;\;\;\;\;[ c \rightarrow A!d \\
& \;\;\;\;\;| \lnot c \rightarrow B!d \\
& \;\;\;]] \\
\end{align*}
Without altering the set of transitions because the selection is deterministic,
and therefore, these two programs are bisimilar.

This transformation is somewhat impractical, as a nondeterministic selection
statement corresponds to additional circuit elements when synthesized.

\subsection{Weak Bisimulation}

Weak bisimulation is a form of bisimulation where only the labeled transitions
are considered.

\subsubsection{Process Decomposition}

Process decomposition is a common parallelism-increasing CHP transformation.  In
general, it involves taking programs of the form:

\[
...;S;...
\]

And decomposing them into ones of the form:

\[
(...;C;...) || *[[\overline{C} \rightarrow S; C]]
\]

Where C is a dataless channel action on a fresh channel (directionality has been
omitted, as dataless sends and receives are symmetric modulo variable renaming).

This transformation will only add a single $\tau$ action, as the channel C has
been explicitly declared to be fresh.  However, this transformation will not
add any additional parallelism, as all of the sequencing will be preserved. If
$S$ cannot perform any channel actions, then we can make an additional
transformation:

\[
(...;C;...) || *[[\bar{C} \rightarrow C; S]]
\]

And now we have increased parallelism, as the statements in $S$ have been
removed from the sequential execution path, and placed on a parallel one.

To avoid shared variables, it may be the case that several statements must be
decomposed at once, such as in:

\[
*[S_1; x := x + 1; S_2; [ c \rightarrow x := 0 \talloblong \lnot c \rightarrow \texttt{skip} ]; S_3; A!x ] 
\]

If none of $S_1$, $S_2$ and $S_3$ contain any actions on $x$, we can
move all of the actions on $x$ into a separate process resulting in:

\begin{align*}
& *[S_1; I; S_2; [ c \rightarrow J \talloblong \lnot c \rightarrow \texttt{skip} ]; S_3; K] \\
& || *[[\;\bar{I} \rightarrow x := x + 1; I \\
&\;\;\;\;\;\;\talloblong \bar{J} \rightarrow x := 0; J \\
&\;\;\;\;\;\;\talloblong \bar{K} \rightarrow  A!x; K \\
&]]
\end{align*}

Again, $I$, $J$, and $K$ are dataless channel actions, so directionality has
been omitted. This process can be re-ordered into:

\begin{align*}
& *[S_1; I; S_2; [ c \rightarrow J \talloblong \lnot c \rightarrow \texttt{skip} ]; S_3; K] \\
& || *[[\;\bar{I} \rightarrow I; x := x + 1 \\
&\;\;\;\;\;\;\talloblong \bar{J} \rightarrow J; x := 0 \\
&\;\;\;\;\;\;\talloblong \bar{K} \rightarrow  A!x; K \\
&]]
\end{align*}

As both of these systems only have one externally-visible channel action (on
$A$), their labeled transition systems will be the same modulo additional $\tau$
transitions from the $I$, $J$, and $K$ internal channel actions. Note that we do
need to know that $x$ does not occur in $S_1$, $S_2$ or $S_3$ for this to hold,
as $c$ must not have any dependencies on $x$. However, given that all of these
conditions hold, this final process will weakly bisimulate the original process.

\end{document}
